# -*- coding: utf-8 -*-
"""NN_CA1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kR0jC5fFOpZsyjv1fmASgLl-Rp9j6hWv
"""

##RBF Implementation
from scipy.io import loadmat
import pandas as pd
import numpy as np
import math
import random
from scipy.spatial import distance

#Load matlab file using loadmat, available in scipy library 
data_test = loadmat('data_test.mat')
data_train = loadmat('data_train.mat')
label_train = loadmat('label_train.mat')

#Gt the data and the labels from the file
db_data_train = data_train["data_train"]
db_label_train = label_train["label_train"]
db_data_test = data_test["data_test"]

#Randomly select the no of centers . Test with different values to get different results
num_centers = 200

#Initialize the weight and center matrix to zero
db_weight = np.zeros([num_centers,1])
centers = np.zeros([num_centers,33])
index_seed = random.sample(range(0,329), num_centers)

#Calculate the centers based on the index seed calculated
for i in range(num_centers):
    centers[i,:] = db_data_train[index_seed[i]]
    
#Calculate the eucledian distance needed to calculate sigma.
d_max = 0
for i in range(num_centers):
    for j in range(num_centers):
        if distance.euclidean(centers[i], centers[j]) > d_max:
            d_max = distance.euclidean(centers[i], centers[j])

#print(db_data_train)
#print(db_data_test)
#print(db_label_train)
#print(db_weight)

#For Only 2 Centers. Each Center for each Class
db_class1 = np.zeros([1,33])
db_class2 = np.zeros([1,33])
num_class_1 = 0
num_class_2 = 0

for i in range(len(db_data_train)):
    if(db_label_train[i] == 1):
        db_class1 += db_data_train[i,:]
        num_class_1 += 1
    elif(db_label_train[i] == -1):
        db_class2 += db_data_train[i,:]
        num_class_2 += 1

db_avg1 = db_class1/num_class_1
db_avg2 = db_class2/num_class_2

#Calculate Sigma based on Centers. sigma = dmax/sqrt(2m). m is number of centers. dmax is max distance between centers
ligma = d_max/math.sqrt(2*num_centers)

#Calculate phi (F=phi*w)
def fi(x,c,sigma):
    db_phi = np.zeros([len(x),len(c)])
    for i in range(len(x)):
        for j in range(len(c)):
            xcj = np.linalg.norm(x[i]-c[j])
            db_phi[i,j] = math.exp(-(xcj*xcj)/(2*sigma*sigma))
            
    return db_phi

db_fi = fi(db_data_train, centers, ligma)

#Calculate the weight using the pseudo inverse function available in numpy
db_weight = np.matmul(np.linalg.pinv(db_fi),db_label_train)

#print(db_weight)

#Evaluation of accuracy on the train data set
def acc(x,lablez, centers, sigma, w):
    num_corr = 0
    predicts = np.matmul(fi(x, centers, sigma), w) 
    threshold = np.average(np.unique(lablez))
    for i in range(len(predicts)):
      if predicts[i] > threshold:
        predicts[i] = 1
      else:
        predicts[i] = -1
    for i in range(len(predicts)):
      if (predicts[i] == lablez[i]):
        num_corr +=1 
    acc = num_corr/len(x)
    return acc

print("Accuracy:",acc(db_data_train,db_label_train, centers, ligma, db_weight))


#Prediction on the test data set to get the class labels
prediction = np.matmul(fi(db_data_test, centers, ligma), db_weight)
for i in range(len(prediction)):
      if prediction[i] > 0:
        prediction[i] = 1
      else:
        prediction[i] = -1
print("Class labels: \n",prediction.astype(int))




#SVM

from scipy.io import loadmat

##Load file 
data_test = loadmat('data_test.mat')
data_train = loadmat('data_train.mat')
label_train = loadmat('label_train.mat')
label_test = loadmat('label_test.mat')

## Get the data and the labels from the file 
db_data_train = data_train["data_train"]
db_label_train = label_train["label_train"]
db_data_test = data_test["data_test"]
db_label_test = label_test["label_test"]

##Train and Test variables

X_train = db_data_train
y_train = db_label_train
X_test = db_data_test
y_test = db_label_test

##Import SVM library from sklearn

from sklearn.svm import SVC
svclassifier = SVC(kernel='rbf', gamma='auto') #For Gaussian kernel, use 'rbf' for the Kernel parameter of the SVC class.
##Hyperparamater gamma can be changed between scale and auto

svclassifier.fit(X_train, y_train.ravel())

from sklearn.metrics import classification_report, confusion_matrix

y_val = svclassifier.predict(X_train)
##Evaluation of accuracy and classification report
print("Confusion Matrix & Classification Report : \n", confusion_matrix(y_train, y_val))
print(classification_report(y_train, y_val))

##Prediction
y_pred = svclassifier.predict(X_test)
print("Predicted labels:",y_pred)

#print(confusion_matrix(y_test, y_pred))
#print(classification_report(y_test, y_pred))
#The output of the Kernel SVM with Gaussian kernel looks like this:
